# Pewlett-Hackard-Analysis
Performing analysis of company employee data by utilizng the dynamic ability of the relational database PostgresSQL to transform and query data.

- combining data 
uploading 
- extracting 
-transofrming 
- fitlering 
-joins 

##  Resources 
- Python 3.7.6, JupyterLab 2.26
- [PostgreSQL 12.2](https://www.postgresql.org/), [Pgadmin 4.20](https://www.pgadmin.org/) 
- Data 

## Overview 
The purpose of this project is to perform analysis on a large-scale of employee data for a company with over 30,000 employees.
The company Pewlett Hackard is reviewing staffing metrics, namely retirement and needs assistance wrangling the data that will help transalte who may be and is eleigible fore retirement. 

## Data Process  
- Data Modeling [ERD Image]<br>
  Through creating an Entity Relationship Diagram we are able to [map out our database schema](https://github.com/DonnieData/Pewlett-Hackard-Analysis/blob/main/Resources/query_schema_0.png) as well as relationships, which is how our various data files will interact with each other as tables within the database. 
 
  
- Data  Wrangling <br>
With the schema of the database mapped out and created we can then import our company data into the database(in the form of csv files of various sizes).
Since datatypes and rules are already defined for the database, we ca nensure dat aintegrity and  a trustworthy analysis. 

importing/wrangling/ transforming. joining 

- Data transofrming/ analyzzing <br>


-data mapping  (ERD)
- database setup / data shaping  ( create table) * screenshot of query to create tables
- data importing 

-data anaylsis and querying  

## Results 
- results of query 
## Summary 
analysis of results maybe throw in some  extra percentage ratios etc 
- How many roles will need to be filled as the "silver tsunami" begins to make an impact?
- Are there enough qualified, retirement-ready employees in the departments to mentor the next generation of Pewlett Hackard employees?



